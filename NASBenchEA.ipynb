{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "name": "NASBench.ipynb",
            "provenance": [],
            "collapsed_sections": [],
            "toc_visible": true,
        },
        "kernelspec": {
            "name": "python3",
            "language": "python",
            "display_name": "Python 3 (ipykernel)",
        },
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Some of this code is Copyright 2019 Google LLC\n",
                "\n",
                'Licensed under the Apache License, Version 2.0 (the "License");\n',
                "you may not use this file except in compliance with the License.\n",
                "You may obtain a copy of the License at\n",
                "\n",
                "    https://www.apache.org/licenses/LICENSE-2.0\n",
                "\n",
                "Unless required by applicable law or agreed to in writing, software\n",
                'distributed under the License is distributed on an "AS IS" BASIS,\n',
                "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                "See the License for the specific language governing permissions and\n",
                "limitations under the License.",
            ],
            "metadata": {"collapsed": false},
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "vl1oLYux3FhJ",
                "colab": {"base_uri": "https://localhost:8080/", "height": 853},
                "outputId": "260484df-3a86-48ef-88a4-f8e441d524bc",
            },
            "source": [
                "# Uncomment the below line to download the dataset (approx. 2gb)\n",
                "# !curl -O https://storage.googleapis.com/nasbench/nasbench_full.tfrecord",
            ],
            "execution_count": 1,
            "outputs": [],
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "outputs": [],
            "source": [
                "# Initialize the NASBench object which parses the raw data into memory\n",
                "# This may take a few minutes, about 2 on my machine\n",
                "import copy\n",
                "import numpy as np\n",
                "import random\n",
                "from nasbench import api\n",
                "from typing import List\n",
                "from nasbench.api import ModelSpec\n",
                "from dataclasses import dataclass\n",
                "from functools import lru_cache\n",
                "from tqdm.notebook import tqdm",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset from file... This may take a few minutes...\n",
                        "WARNING:tensorflow:From d:\\nas-bench\\venv\\lib\\site-packages\\nasbench\\api.py:146: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use eager execution and: \n",
                        "`tf.data.TFRecordDataset(path)`\n",
                        "Loaded dataset in 136 seconds\n",
                    ],
                }
            ],
            "source": ['nasbench = api.NASBench("nasbench_full.tfrecord")'],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "metadata": {"id": "oFhFRmck7NzM"},
            "source": [
                'INPUT = "input"\n',
                'OUTPUT = "output"\n',
                'CONV3X3 = "conv3x3-bn-relu"\n',
                'CONV1X1 = "conv1x1-bn-relu"\n',
                'MAXPOOL3X3 = "maxpool3x3"\n',
                "\n",
                "NUM_VERTICES = 7\n",
                "MAX_EDGES = 9\n",
                "\n",
                "EDGE_SPOTS = NUM_VERTICES * (NUM_VERTICES - 1) / 2  # Upper triangular matrix\n",
                "OP_SPOTS = NUM_VERTICES - 2  # Input/output vertices are fixed\n",
                "\n",
                "ALLOWED_OPS = [CONV3X3, CONV1X1, MAXPOOL3X3]\n",
                "ALLOWED_EDGES = [0, 1]  # Binary adjacency matrix\n",
                "\n",
                "RNG_SEED = 42",
            ],
            "execution_count": 5,
            "outputs": [],
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class ModelData:\n",
                '    """\n',
                "    Wraps up resulting data from NASBench.query in a class for code cleanliness.\n",
                '    """\n',
                "    matrix: List[List[int]]\n",
                "    operations: List[str]\n",
                "    parameters: int\n",
                "    train_time: float\n",
                "    train_accuracy: float\n",
                "    valid_accuracy: float\n",
                "    test_accuracy: float\n",
                "\n",
                "\n",
                "class SpecWrapper(ModelSpec):\n",
                '    """\n',
                "    Wraps a model to allow easier access to the resulting data of the model.\n",
                '    """\n',
                "\n",
                '    def __lt__(self, other: "SpecWrapper"):\n',
                "        if not (isinstance(other, SpecWrapper)):\n",
                "            return False\n",
                "\n",
                "        return self.get_data().test_accuracy < other.get_data().test_accuracy\n",
                "\n",
                "    @lru_cache(maxsize=1)\n",
                "    def get_data(self):\n",
                '        """\n',
                "        Get resultant data from NASBench.\n",
                "        The LRU cache ensures we don't add time to the budget counters multiple times.\n",
                "        :return:\n",
                '        """\n',
                "        data = nasbench.query(self)\n",
                "        return ModelData(\n",
                "            data['module_adjacency'],\n",
                "            data['module_operations'],\n",
                "            data['trainable_parameters'],\n",
                "            data['training_time'],\n",
                "            data['train_accuracy'],\n",
                "            data['validation_accuracy'],\n",
                "            data['test_accuracy']\n",
                "        )\n",
                "\n",
                "    def __repr__(self):\n",
                "        return self.hash_spec(nasbench.config['available_ops'])",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "outputs": [
                {
                    "data": {
                        "text/plain": "  0%|          | 0/423624 [00:00<?, ?it/s]",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "bd45bb0e7f8649459bddd1a9da13209e",
                        },
                    },
                    "metadata": {},
                    "output_type": "display_data",
                }
            ],
            "source": [
                "n_specs = len(list(nasbench.hash_iterator()))\n",
                "all_specs = tqdm(map(lambda x: nasbench.get_metrics_from_hash(x), nasbench.hash_iterator()), total=n_specs)\n",
                "all_specs = [SpecWrapper(matrix=spec[0]['module_adjacency'], ops=spec[0]['module_operations']) for spec in all_specs]",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "outputs": [],
            "source": [
                "def random_spec() -> SpecWrapper:\n",
                "    return random.choice(all_specs)",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "outputs": [],
            "source": [
                "def sel_best(population: List[SpecWrapper], k: int) -> List[SpecWrapper]:\n",
                '    """\n',
                "    Select the top k candidates amongst the entire population.\n",
                "    :param population: The population to select from.\n",
                "    :param k: The number of top individuals to select.\n",
                "    :return: The selected individuals.\n",
                '    """\n',
                "    population.sort()\n",
                "    return population[-k:]\n",
                "\n",
                "\n",
                "def sel_random(population: List[SpecWrapper], k: int) -> List[SpecWrapper]:\n",
                '    """\n',
                "    Select k individuals from the population at random.\n",
                "    :param population: The population to select from.\n",
                "    :param k: The number of individuals to select.\n",
                "    :return: The selected individuals.\n",
                '    """\n',
                "    return random.sample(population, k)\n",
                "\n",
                "\n",
                "def sel_tournament(population: List[SpecWrapper], k: int, n: int) -> List[SpecWrapper]:\n",
                '    """\n',
                "    Select the n best individuals from amongst k randomly selected candidates.\n",
                "    :param population: The population to select from.\n",
                "    :param k: The number of candidates to randomly select.\n",
                "    :param n: The number of top candidates to be returned.\n",
                "    :return: The selected individuals.\n",
                '    """\n',
                "    candidates = sel_random(population, k)\n",
                "    return sel_best(candidates, n)\n",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "outputs": [],
            "source": [
                "def run_random_search(k: int, max_time: float):\n",
                '    """\n',
                "    Runs a simulated random search for a fixed amount of time. Actual time taken will be\n",
                "    relatively quick, only the simulated time is considered. Will return all evaluated models,\n",
                "    along with the k best models found.\n",
                "    :param k: Number of best models to return\n",
                "    :param max_time_budget: The amount of simulated time to expend.\n",
                "    :return: All models evaluated, along with the best k models.\n",
                '    """\n',
                "\n",
                "    # nasbench tracks time taken with each query, effectively simulating full\n",
                "    # training, as we can query how long into the training we would be if we\n",
                "    # were training ourselves. we reset the counters at the top of each experiment\n",
                "    np.random.seed(RNG_SEED)\n",
                "    random.seed(RNG_SEED)\n",
                "    nasbench.reset_budget_counters()\n",
                "\n",
                "    best: List[SpecWrapper] = []\n",
                "    models: List[SpecWrapper] = []\n",
                "    unique_hashes: List[str] = []\n",
                "    collisions: int = 0\n",
                "\n",
                "    time_spent, _ = nasbench.get_budget_counters()\n",
                "    while time_spent < max_time:\n",
                "        last_time = time_spent\n",
                "        spec = random_spec()\n",
                "        spec_hash = spec.hash_spec(nasbench.config['available_ops'])\n",
                "        assert time_spent == last_time\n",
                "\n",
                "        if spec_hash in unique_hashes:\n",
                "            collisions += 1\n",
                "            continue\n",
                "        else:\n",
                "            unique_hashes.append(spec_hash)\n",
                "\n",
                "        models.append(spec)\n",
                "        best = sel_best(models, k)\n",
                "        time_spent, _ = nasbench.get_budget_counters()\n",
                "\n",
                '    print(f"{len(unique_hashes)} unique models during random search.")\n',
                '    print(f"{collisions} collisions during random search.")\n',
                "\n",
                "    return models, best",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "241 unique models during random search.\n",
                        "0 collisions during random search.\n",
                    ],
                }
            ],
            "source": ["all, best = run_random_search(10, 5e8)"],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "outputs": [],
            "source": [
                "def run_evolution_search(\n",
                "    max_time_budget=5e6, population_size=50, tournament_size=10, mutation_rate=1.0\n",
                "):\n",
                '    """Run a single roll-out of regularized evolution to a fixed time budget."""\n',
                "    nasbench.reset_budget_counters()\n",
                "    times, best_valids, best_tests = [0.0], [0.0], [0.0]\n",
                "    population = []  # (validation, spec) tuples\n",
                "\n",
                "    # For the first population_size individuals, seed the population with randomly\n",
                "    # generated cells.\n",
                "    for _ in range(population_size):\n",
                "        spec = random_spec()\n",
                "        data = nasbench.query(spec)\n",
                "        time_spent, _ = nasbench.get_budget_counters()\n",
                "        times.append(time_spent)\n",
                '        population.append((data["validation_accuracy"], spec))\n',
                "\n",
                '        if data["validation_accuracy"] > best_valids[-1]:\n',
                '            best_valids.append(data["validation_accuracy"])\n',
                '            best_tests.append(data["test_accuracy"])\n',
                "        else:\n",
                "            best_valids.append(best_valids[-1])\n",
                "            best_tests.append(best_tests[-1])\n",
                "\n",
                "        if time_spent > max_time_budget:\n",
                "            break\n",
                "\n",
                "    # After the population is seeded, proceed with evolving the population.\n",
                "    while True:\n",
                "        sample = random_combination(population, tournament_size)\n",
                "        best_spec = sorted(sample, key=lambda i: i[0])[-1][1]\n",
                "        new_spec = mutate_spec(best_spec, mutation_rate)\n",
                "\n",
                "        data = nasbench.query(new_spec)\n",
                "        time_spent, _ = nasbench.get_budget_counters()\n",
                "        times.append(time_spent)\n",
                "\n",
                "        # In regularized evolution, we kill the oldest individual in the population.\n",
                '        population.append((data["validation_accuracy"], new_spec))\n',
                "        population.pop(0)\n",
                "\n",
                '        if data["validation_accuracy"] > best_valids[-1]:\n',
                '            best_valids.append(data["validation_accuracy"])\n',
                '            best_tests.append(data["test_accuracy"])\n',
                "        else:\n",
                "            best_valids.append(best_valids[-1])\n",
                "            best_tests.append(best_tests[-1])\n",
                "\n",
                "        if time_spent > max_time_budget:\n",
                "            break\n",
                "\n",
                "    return times, best_valids, best_tests",
            ],
            "metadata": {"collapsed": false, "pycharm": {"name": "#%%\n"}},
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "HMfF2zXxpQNA",
                "colab": {"base_uri": "https://localhost:8080/", "height": 187},
                "outputId": "edff2ca4-8a55-4537-838a-dedc7a9f360b",
                "pycharm": {"name": "#%%\n"},
            },
            "source": [
                "# Run random search and evolution search 10 times each. This should take a few\n",
                "# minutes to run. Note that each run would have taken days of compute to\n",
                "# actually train and evaluate if the dataset were not precomputed.\n",
                "random_data = []\n",
                "evolution_data = []\n",
                "for repeat in range(10):\n",
                '    print("Running repeat %d" % (repeat + 1))\n',
                "    times, best_valid, best_test = run_random_search()\n",
                "    random_data.append((times, best_valid, best_test))\n",
                "\n",
                "    times, best_valid, best_test = run_evolution_search()\n",
                "    evolution_data.append((times, best_valid, best_test))\n",
            ],
            "execution_count": 13,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running repeat 1\n",
                        "Running repeat 2\n",
                        "Running repeat 3\n",
                        "Running repeat 4\n",
                        "Running repeat 5\n",
                        "Running repeat 6\n",
                        "Running repeat 7\n",
                        "Running repeat 8\n",
                        "Running repeat 9\n",
                        "Running repeat 10\n",
                    ],
                }
            ],
        },
    ],
}
